{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a108af04",
   "metadata": {},
   "source": [
    "This is a starter notebook for the project, you'll have to import the libraries you'll need, you can find a list of the ones available in this workspace in the requirements.txt file in this workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc99032-628c-4021-bfe2-ce6b6f1a176c",
   "metadata": {},
   "source": [
    "\n",
    "# Project: Personalized Real Estate Agent\n",
    "\n",
    "An example of AI agent built by Python, Langchain, Vector Database and OpenAI's API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b22ef-70b8-43df-8e1e-086711b06d27",
   "metadata": {},
   "source": [
    "## Step 1: Synthetic Data Generation\n",
    "\n",
    "Generate a list of at least 10 real estates using LLM, \n",
    "which will be served as the data source to store into the vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6554fd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/x_coder/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import Python Packages\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, NonNegativeInt\n",
    "from typing import List\n",
    "from random import sample \n",
    "from langchain.document_loaders.csv_loader import CSVLoader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c5a61e-f5cf-46b2-b9ea-b70a48040ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1.1: Initialize OpenAI\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model=model_name, temperature=0, api_key=OPENAI_API_KEY)\n",
    "#llm = OpenAI(model_name = model_name, temperature=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c7c8e2-8af3-489e-a069-838d80124aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"title\": {\"description\": \"The name or title of a house\", \"title\": \"Title\", \"type\": \"string\"}, \"bedroom\": {\"description\": \"Number of bedroom for a house\", \"title\": \"Bedroom\", \"type\": \"integer\"}, \"bathroom\": {\"description\": \"Number of bathroom for a house\", \"title\": \"Bathroom\", \"type\": \"integer\"}, \"garage\": {\"description\": \"Number of garage for a house\", \"title\": \"Garage\", \"type\": \"integer\"}, \"price_usd\": {\"description\": \"The price of a house in USD\", \"title\": \"Price Usd\", \"type\": \"integer\"}, \"size_sqft\": {\"description\": \"The size of a house in square feet\", \"title\": \"Size Sqft\", \"type\": \"integer\"}, \"description\": {\"description\": \"The 200-word description of a house\", \"title\": \"Description\", \"type\": \"string\"}, \"neighborhood\": {\"description\": \"The brief summary or name of the neighborhood for the house\", \"title\": \"Neighborhood\", \"type\": \"string\"}, \"neighborhood_details\": {\"description\": \"The 200-word description of the neighborhood\", \"title\": \"Neighborhood Details\", \"type\": \"string\"}}, \"required\": [\"title\", \"bedroom\", \"bathroom\", \"garage\", \"price_usd\", \"size_sqft\", \"description\", \"neighborhood\", \"neighborhood_details\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1.2: Define data model for parser\n",
    "\n",
    "class RealEstate(BaseModel):\n",
    "    title: str = Field(description=\"The name or title of a house\")\n",
    "    bedroom: int = Field(description=\"Number of bedroom for a house\")\n",
    "    bathroom: int = Field(description=\"Number of bathroom for a house\")\n",
    "    garage: int = Field(description=\"Number of garage for a house\")\n",
    "    price_usd: int = Field(description=\"The price of a house in USD\")\n",
    "    size_sqft: int = Field(description=\"The size of a house in square feet\") \n",
    "    description: str = Field(description=\"The 200-word description of a house\")\n",
    "    neighborhood: str = Field(description=\"The brief summary or name of the neighborhood for the house\")\n",
    "    neighborhood_details: str = Field(description=\"The 200-word description of the neighborhood\")\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=RealEstate)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f81230e4-1419-46d7-be64-5ecb034836a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House data source is ready!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1.3: Ask LLM to generate a list of real estate and save to a text file \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "HOUSE_FILE_NAME_CSV = \"Listings.csv\"\n",
    "HOUSE_FILE_NAME_TXT = \"Listings.txt\"\n",
    "\n",
    "def generate_house_list():\n",
    "    question = \"\"\"\n",
    "    Generate 11 houses which are currently for sale in the US market, \n",
    "    earch house should include these properties: \n",
    "    title, \n",
    "    number of bedrooms,\n",
    "    number of bathrooms,\n",
    "    number of garadges\n",
    "    price (integer in USD), \n",
    "    size (integer in squre feet), \n",
    "    description of the house with at least 200 words, \n",
    "    neighborhood, \n",
    "    description of neighborhood with at least 100 words\n",
    "    \"\"\"\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(RealEstate, method=\"json_mode\")\n",
    "    listings = structured_llm.invoke(question + \"\\n\\n\" + parser.get_format_instructions())\n",
    "    return listings\n",
    "\n",
    "def save_house_list_to(file_name: str, list_dic): \n",
    "    df = pd.DataFrame.from_dict(list_dic)\n",
    "    df.to_csv(file_name)\n",
    "\n",
    "\n",
    "# if the house list file is not there, generate it from LLM\n",
    "if not os.path.isfile(HOUSE_FILE_NAME_CSV):\n",
    "    houses = generate_house_list()\n",
    "    save_house_list_to(HOUSE_FILE_NAME_CSV, houses[\"houses\"])\n",
    "\n",
    "\n",
    "print(\"House data source is ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8712f539-5ae5-4f9c-b092-f2564d7f5082",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Semantic Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8c8d5cd-0e83-4a99-845a-0dc6688f6887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.chroma.Chroma object at 0x1254204c0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2.1: Create a vector database from the house list\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "DATABASE_FILE = \"listings_chroma_db\"\n",
    "\n",
    "if not os.path.isfile(DATABASE_FILE):\n",
    "    loader = CSVLoader(file_path = HOUSE_FILE_NAME_CSV)\n",
    "    docs = loader.load()\n",
    "\n",
    "    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    split_docs = splitter.split_documents(docs)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = Chroma.from_documents(split_docs, embeddings, persist_directory= DATABASE_FILE)\n",
    "else: \n",
    "    db = Chroma(persist_directory=DATABASE_FILE, embedding_function=embedding_function)\n",
    "\n",
    "print(db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3754db-d93a-441c-89f8-3f22e0bbff12",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Augmented Response Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d448697-dcf3-434e-b851-57fed915940b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
